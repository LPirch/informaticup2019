%!TEX root = paper.tex

\section{Threat Model}
\label{sec:threatmodel}
In the following, the adversarial threat model shall be identified.
This is an important step to systematically explore suitable attack techniques and to recognize which scientific insights apply to this use case.
The characterization of potential misclassifications can be grouped into four categories, which are adapted from \citeauthor{papernot2016limitations}\cite{papernot2016limitations}.
\begin{description}
	\item [Confidence Reduction.] The output confidence is reduced.
	\item [Misclassification.] The classification is changed to any other class than the original one.
	\item [Targeted Misclassification.] Starting from any (or even an empty) input, perturbations are generated such that the output is a certain class.
	\item [Source/Target Misclassification] The classification output is forced to be a specific class, starting from a given input. For example, this corresponds to altering an otherwise correctly classified image in a way that makes it be classified as a certain different class.
\end{description}
In the case on hand, the adversarial modifications take place after the model has been trained and the malicious samples are crafted with the intention of provoking a misclassification.
Formally, any attack that corresponds to a lower category in this list also fits an upper one since categories are sorted by adversarial strength increasing from the top to the bottom.
The minimal requirement of this challenge is a simple misclassification since the only requirement is that the generated image shall be classified as a traffic sign.
Moreover, the threat model can further specified as an almost pure black-box setting in which the target model can only be accessed as an oracle $X \rightarrow Y$ where $X$ is an input and $Y$ is a label.
Fetching a prediction returns the confidences of the top five predicted classes and is restricted to one request per second.
The only additional known information is which training data has been used~\cite{papernot2016limitations} and that the utilized ML algorithm is a neural network.
